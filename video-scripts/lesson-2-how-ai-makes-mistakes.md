Why does A I make mistakes? Understanding this helps you know what to verify.

A I generates text by predicting what words should come next based on patterns in training data. It doesn't actually know things the way humans do. It's very sophisticated pattern matching.

When A I lacks information, it often fills gaps with plausible sounding content. This is called hallucination. A I doesn't know it's making things up. It produces confident text regardless of accuracy.

Common A I mistakes include inventing citations. A I frequently cites papers, books, and articles that don't exist. The citations look real but lead nowhere.

Fabricating statistics. A I may provide specific numbers that sound authoritative but are completely made up.

Confusing facts. A I may mix up similar people, events, or concepts, combining accurate elements incorrectly.

Outdated information. A I has training cutoffs and may present old information as current.

Overconfident assertions. A I rarely expresses appropriate uncertainty, even when it should.

The key insight is that A I sounds equally confident whether it's right or wrong. Confidence is no indicator of accuracy.

This means you can't rely on how authoritative A I sounds. You need external verification for anything important.
